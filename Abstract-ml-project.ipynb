{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"train-1.json\")\n",
    "test = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9658, 11)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9655.000000</td>\n",
       "      <td>9658.000000</td>\n",
       "      <td>9658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2015.384878</td>\n",
       "      <td>31.994202</td>\n",
       "      <td>36.994823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.562034</td>\n",
       "      <td>24.189335</td>\n",
       "      <td>191.394827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>9094.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year   references    citations\n",
       "count  9655.000000  9658.000000  9658.000000\n",
       "mean   2015.384878    31.994202    36.994823\n",
       "std       7.562034    24.189335   191.394827\n",
       "min    1979.000000     0.000000     0.000000\n",
       "25%    2015.000000    19.000000     2.000000\n",
       "50%    2018.000000    29.000000     8.000000\n",
       "75%    2020.000000    41.000000    25.000000\n",
       "max    2021.000000   668.000000  9094.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2015.886000</td>\n",
       "      <td>32.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.922494</td>\n",
       "      <td>22.417259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1979.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>304.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year   references\n",
       "count  1000.000000  1000.000000\n",
       "mean   2015.886000    32.429000\n",
       "std       6.922494    22.417259\n",
       "min    1979.000000     0.000000\n",
       "25%    2015.000000    20.000000\n",
       "50%    2018.000000    29.000000\n",
       "75%    2020.000000    41.000000\n",
       "max    2021.000000   304.000000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doi                  0\n",
       "title                0\n",
       "abstract           159\n",
       "authors              0\n",
       "venue                0\n",
       "year                 3\n",
       "references           0\n",
       "topics               0\n",
       "is_open_access       0\n",
       "fields_of_study    136\n",
       "citations            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_open_access      0\n",
       "doi                 0\n",
       "title               0\n",
       "fields_of_study    13\n",
       "abstract           19\n",
       "year                0\n",
       "venue               0\n",
       "references          0\n",
       "authors             0\n",
       "topics              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null values on abstract for train and test data\n",
    "df_train[\"abstract\"] = df_train[\"abstract\"].fillna(\"\")\n",
    "df_test[\"abstract\"] = df_test[\"abstract\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Word embeddings are an active topic in the NLP research community. State-of-the-art neural models achieve high performance on downstream tasks, albeit at the cost of computationally expensive training. Cost aware solutions require cheaper models that still achieve good performance. We present several reproduction studies of intrinsic evaluation tasks that evaluate non-contextual word representations in multiple languages. Furthermore, we present 50-8-8, a new data set for the outlier identification task, which avoids limitations of the original data set, such as ambiguous words, infrequent words, and multi-word tokens, while increasing the number of test cases. The data set is expanded to contain semantic and syntactic tests and is multilingual (English, German, and Italian). We provide an in-depth analysis of word embedding models with a range of hyper-parameters. Our analysis shows the suitability of different models and hyper-parameters for different tasks and the greater difficulty of representing German and Italian languages.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"abstract\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pretraining NLP models with variants of Masked Language Model (MLM) objectives has recently led to a significant improvements on many tasks. This paper examines the benefits of pretrained models as a function of the number of training samples used in the downstream task. On several text classification tasks, we show that as the number of training examples grow into the millions, the accuracy gap between finetuning BERT-based model and training vanilla LSTM from scratch narrows to within 1%. Our findings indicate that MLM-based models might reach a diminishing return point as the supervised data size increases significantly.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"abstract\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "Punctuations = string.punctuation\n",
    "print(Punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_clean = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    text_rc = re.sub('[0-9]+', '', text_clean)\n",
    "    tokens = re.split('\\W+', text_rc)\n",
    "    text = [word for word in tokens if word not in Stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_train = df_train[[\"abstract\"]]\n",
    "abstract_train['clean_abstract_train'] = abstract_train[\"abstract\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_test = df_test[[\"abstract\"]]\n",
    "abstract_test['clean_abstract_test'] = abstract_test[\"abstract\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abstract_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sequence-to-sequence models usually transfer a...</td>\n",
       "      <td>[sequencetosequence, models, usually, transfer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pretraining NLP models with variants of Masked...</td>\n",
       "      <td>[pretraining, nlp, models, variants, masked, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the wide-spread belief, although ...</td>\n",
       "      <td>[according, widespread, belief, although, ngan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A number of psycholinguistic studies have fact...</td>\n",
       "      <td>[number, psycholinguistic, studies, factoriall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This paper describes our submission to theSemE...</td>\n",
       "      <td>[paper, describes, submission, thesemeval, tas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  Sequence-to-sequence models usually transfer a...   \n",
       "1  Pretraining NLP models with variants of Masked...   \n",
       "2  According to the wide-spread belief, although ...   \n",
       "3  A number of psycholinguistic studies have fact...   \n",
       "4  This paper describes our submission to theSemE...   \n",
       "\n",
       "                                 clean_abstract_test  \n",
       "0  [sequencetosequence, models, usually, transfer...  \n",
       "1  [pretraining, nlp, models, variants, masked, l...  \n",
       "2  [according, widespread, belief, although, ngan...  \n",
       "3  [number, psycholinguistic, studies, factoriall...  \n",
       "4  [paper, describes, submission, thesemeval, tas...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the other abstract\n",
    "abstract_train.drop(['abstract'], inplace = True, axis = 1)\n",
    "abstract_test.drop(['abstract'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_abstract_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[semantic, role, labeling, srl, crucial, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[word, embeddings, active, topic, nlp, researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[propose, new, shared, task, tactical, datatot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[evaluate, semantic, parser, based, characterb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paper, gauge, utility, generalpurpose, opendo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                clean_abstract_train\n",
       "0  [semantic, role, labeling, srl, crucial, natur...\n",
       "1  [word, embeddings, active, topic, nlp, researc...\n",
       "2  [propose, new, shared, task, tactical, datatot...\n",
       "3  [evaluate, semantic, parser, based, characterb...\n",
       "4  [paper, gauge, utility, generalpurpose, opendo..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the cleaned abstract to the train and test dataset \n",
    "df_train['abstract'] = abstract_train['clean_abstract_train']\n",
    "df_test['abstract'] = abstract_test['clean_abstract_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.3115/v1/P15-1039</td>\n",
       "      <td>Generating High Quality Proposition Banks for ...</td>\n",
       "      <td>[semantic, role, labeling, srl, crucial, natur...</td>\n",
       "      <td>[A. Akbik, Laura Chiticariu, Marina Danilevsky...</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>39</td>\n",
       "      <td>[Semantic role labeling]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.18653/v1/2020.eval4nlp-1.12</td>\n",
       "      <td>One of these words is not like the other: a re...</td>\n",
       "      <td>[word, embeddings, active, topic, nlp, researc...</td>\n",
       "      <td>[Jesper Brink Andersen, Mikkel Bak Bertelsen, ...</td>\n",
       "      <td>EVAL4NLP</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>44</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.18653/v1/W17-3516</td>\n",
       "      <td>The Code2Text Challenge: Text Generation in So...</td>\n",
       "      <td>[propose, new, shared, task, tactical, datatot...</td>\n",
       "      <td>[Kyle Richardson, Sina Zarrieß, Jonas Kuhn]</td>\n",
       "      <td>INLG</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>30</td>\n",
       "      <td>[Natural language generation, Library (computi...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.18653/v1/S17-2160</td>\n",
       "      <td>The Meaning Factory at SemEval-2017 Task 9: Pr...</td>\n",
       "      <td>[evaluate, semantic, parser, based, characterb...</td>\n",
       "      <td>[Rik van Noord, Johan Bos]</td>\n",
       "      <td>SemEval@ACL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[Parsing, Convolutional neural network, Text-b...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.18653/v1/W15-2205</td>\n",
       "      <td>Semantic Parsing for Textual Entailment</td>\n",
       "      <td>[paper, gauge, utility, generalpurpose, opendo...</td>\n",
       "      <td>[Elisabeth Lien, Milen Kouylekov]</td>\n",
       "      <td>IWPT</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[Textual entailment, Parsing, SemEval, Semanti...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              doi  \\\n",
       "0             10.3115/v1/P15-1039   \n",
       "1  10.18653/v1/2020.eval4nlp-1.12   \n",
       "2            10.18653/v1/W17-3516   \n",
       "3            10.18653/v1/S17-2160   \n",
       "4            10.18653/v1/W15-2205   \n",
       "\n",
       "                                               title  \\\n",
       "0  Generating High Quality Proposition Banks for ...   \n",
       "1  One of these words is not like the other: a re...   \n",
       "2  The Code2Text Challenge: Text Generation in So...   \n",
       "3  The Meaning Factory at SemEval-2017 Task 9: Pr...   \n",
       "4            Semantic Parsing for Textual Entailment   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [semantic, role, labeling, srl, crucial, natur...   \n",
       "1  [word, embeddings, active, topic, nlp, researc...   \n",
       "2  [propose, new, shared, task, tactical, datatot...   \n",
       "3  [evaluate, semantic, parser, based, characterb...   \n",
       "4  [paper, gauge, utility, generalpurpose, opendo...   \n",
       "\n",
       "                                             authors        venue    year  \\\n",
       "0  [A. Akbik, Laura Chiticariu, Marina Danilevsky...          ACL  2015.0   \n",
       "1  [Jesper Brink Andersen, Mikkel Bak Bertelsen, ...     EVAL4NLP  2020.0   \n",
       "2        [Kyle Richardson, Sina Zarrieß, Jonas Kuhn]         INLG  2017.0   \n",
       "3                         [Rik van Noord, Johan Bos]  SemEval@ACL  2017.0   \n",
       "4                  [Elisabeth Lien, Milen Kouylekov]         IWPT  2015.0   \n",
       "\n",
       "   references                                             topics  \\\n",
       "0          39                           [Semantic role labeling]   \n",
       "1          44                                                 []   \n",
       "2          30  [Natural language generation, Library (computi...   \n",
       "3          11  [Parsing, Convolutional neural network, Text-b...   \n",
       "4          26  [Textual entailment, Parsing, SemEval, Semanti...   \n",
       "\n",
       "   is_open_access     fields_of_study  citations  \n",
       "0            True  [Computer Science]         60  \n",
       "1            True  [Computer Science]          1  \n",
       "2            True  [Computer Science]          5  \n",
       "3            True  [Computer Science]          5  \n",
       "4            True  [Computer Science]         10  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>references</th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2021.findings-acl.255</td>\n",
       "      <td>On Sparsifying Encoder Outputs in Sequence-to-...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[sequencetosequence, models, usually, transfer...</td>\n",
       "      <td>2021</td>\n",
       "      <td>FINDINGS</td>\n",
       "      <td>47</td>\n",
       "      <td>[Biao Zhang, Ivan Titov, Rico Sennrich]</td>\n",
       "      <td>[Encoder, Transformer, Automatic summarization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>10.18653/v1/2020.acl-main.200</td>\n",
       "      <td>To Pretrain or Not to Pretrain: Examining the ...</td>\n",
       "      <td>[Computer Science, Mathematics]</td>\n",
       "      <td>[pretraining, nlp, models, variants, masked, l...</td>\n",
       "      <td>2020</td>\n",
       "      <td>ACL</td>\n",
       "      <td>18</td>\n",
       "      <td>[Sinong Wang, Madian Khabsa, Hao Ma]</td>\n",
       "      <td>[Supervised learning, Language model, Document...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>10.18653/v1/W18-0211</td>\n",
       "      <td>Utilization of Nganasan digital resources: a s...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[according, widespread, belief, although, ngan...</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>[L. Fejes]</td>\n",
       "      <td>[Rounding, Lexicon, Tracer, Body of uterus, Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>10.18653/v1/N19-1413</td>\n",
       "      <td>A large-scale study of the effects of word fre...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[number, psycholinguistic, studies, factoriall...</td>\n",
       "      <td>2019</td>\n",
       "      <td>NAACL</td>\n",
       "      <td>52</td>\n",
       "      <td>[Cory Shain]</td>\n",
       "      <td>[Word lists by frequency, Text corpus, Sentenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2021.semeval-1.168</td>\n",
       "      <td>Amherst685 at SemEval-2021 Task 7: Joint Model...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[paper, describes, submission, thesemeval, tas...</td>\n",
       "      <td>2021</td>\n",
       "      <td>SEMEVAL</td>\n",
       "      <td>17</td>\n",
       "      <td>[Brian Zylich, Akshay Gugnani, Gabriel Brookma...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_open_access                                doi  \\\n",
       "0           False  10.18653/v1/2021.findings-acl.255   \n",
       "1            True      10.18653/v1/2020.acl-main.200   \n",
       "2            True               10.18653/v1/W18-0211   \n",
       "3            True               10.18653/v1/N19-1413   \n",
       "4           False     10.18653/v1/2021.semeval-1.168   \n",
       "\n",
       "                                               title  \\\n",
       "0  On Sparsifying Encoder Outputs in Sequence-to-...   \n",
       "1  To Pretrain or Not to Pretrain: Examining the ...   \n",
       "2  Utilization of Nganasan digital resources: a s...   \n",
       "3  A large-scale study of the effects of word fre...   \n",
       "4  Amherst685 at SemEval-2021 Task 7: Joint Model...   \n",
       "\n",
       "                   fields_of_study  \\\n",
       "0               [Computer Science]   \n",
       "1  [Computer Science, Mathematics]   \n",
       "2               [Computer Science]   \n",
       "3               [Computer Science]   \n",
       "4               [Computer Science]   \n",
       "\n",
       "                                            abstract  year     venue  \\\n",
       "0  [sequencetosequence, models, usually, transfer...  2021  FINDINGS   \n",
       "1  [pretraining, nlp, models, variants, masked, l...  2020       ACL   \n",
       "2  [according, widespread, belief, although, ngan...  2018             \n",
       "3  [number, psycholinguistic, studies, factoriall...  2019     NAACL   \n",
       "4  [paper, describes, submission, thesemeval, tas...  2021   SEMEVAL   \n",
       "\n",
       "   references                                            authors  \\\n",
       "0          47            [Biao Zhang, Ivan Titov, Rico Sennrich]   \n",
       "1          18               [Sinong Wang, Madian Khabsa, Hao Ma]   \n",
       "2           8                                         [L. Fejes]   \n",
       "3          52                                       [Cory Shain]   \n",
       "4          17  [Brian Zylich, Akshay Gugnani, Gabriel Brookma...   \n",
       "\n",
       "                                              topics  \n",
       "0  [Encoder, Transformer, Automatic summarization...  \n",
       "1  [Supervised learning, Language model, Document...  \n",
       "2  [Rounding, Lexicon, Tracer, Body of uterus, Cl...  \n",
       "3  [Word lists by frequency, Text corpus, Sentenc...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentA = df_train['abstract']\n",
    "documentB = df_test['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWordsA = [\",\".join(i) for i in documentA] \n",
    "bagOfWordsB = [\",\".join(i) for i in documentB] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(numOfWordsB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF*IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency (TF)\n",
    "the number of times a word appears in a document divided by the total number of words in the document. Every document has its own term frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Data Frequency (IDF)\n",
    "The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "                \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF*IDF \n",
    "TF-IDF is simply the TF multiplied by IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "df = pd.DataFrame([tfidfA, tfidfB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rover,widely,used,method,combine,output,multiple,automatic,speech,recognition,asr,systems,though,effective,basic,approach,variants,suffer,potential,drawbacks,results,depend,order,hypotheses,used,feed,combination,process,ii,applied,combine,long,hypotheses,disregard,possible,differences,transcription,quality,local,level,iii,often,rely,word,confidence,information,address,issues,proposing,segmentbased,rover,hypothesis,ranking,obtained,confidenceindependent,asr,quality,estimation,method,results,english,data,iwslt,iwslt,evaluation,campaigns,significantly,outperform,standard,rover,approximate,two,strong,oracles</th>\n",
       "      <th>propose,joint,event,temporal,relation,extraction,model,shared,representation,learning,structured,prediction,proposed,method,two,advantages,existing,work,first,improves,event,representation,allowing,event,relation,modules,share,contextualized,embeddings,neural,representation,learner,second,avoids,error,propagation,conventional,pipeline,systems,leveraging,structured,inference,learning,methods,assign,event,labels,temporal,relation,labels,jointly,experiments,show,proposed,method,improve,event,extraction,temporal,relation,extraction,stateoftheart,systems,endtoend,f,improved,two,benchmark,datasets,respectively</th>\n",
       "      <th>introduce,new,features,incorporating,semantic,predicateargument,structures,machine,translation,mt,methods,focus,completeness,semantic,structures,translations,well,order,translated,semantic,roles,experiment,translation,rules,contain,core,arguments,predicates,source,side,mt,system,observe,using,rules,significantly,improves,translation,quality,also,present,new,semantic,feature,resembles,language,model,results,show,language,model,feature,also,significantly,improve,mt,results</th>\n",
       "      <th>image,description,new,natural,language,generation,task,aim,generate,humanlike,description,image,evaluation,computergenerated,text,notoriously,difficult,problem,however,quality,image,descriptions,typically,measured,using,unigram,bleu,human,judgements,focus,paper,determine,correlation,automatic,measures,human,judgements,task,estimate,correlation,unigram,smoothed,bleu,ter,rougesu,meteor,human,judgements,two,data,sets,main,finding,unigram,bleu,weak,correlation,meteor,strongest,correlation,human,judgements</th>\n",
       "      <th>paper,propose,architecture,machine,translation,mt,capable,obtaining,multilingual,sentence,representations,incorporating,intermediate,attention,bridge,shared,across,languages,train,model,languagespecific,encoders,decoders,connected,innerattention,layer,encoder,side,attention,bridge,exploits,semantics,language,translation,develops,languageagnostic,meaning,representation,efficiently,used,transfer,learning,present,new,framework,efficient,development,multilingual,neural,machine,translation,nmt,using,model,scheduled,training,tested,approach,systematic,way,multiparallel,data,set,model,achieves,substantial,improvements,strong,bilingual,models,performs,well,zeroshot,translation,demonstrates,ability,abstraction,transfer,learning</th>\n",
       "      <th>ezafe,grammatical,particle,iranian,languages,links,two,words,together,regardless,important,information,conveys,almost,always,indicated,persian,script,resulting,mistakes,reading,complex,sentences,errors,natural,language,processing,tasks,paper,experiment,different,machine,learning,methods,achieve,stateoftheart,results,task,ezafe,recognition,transformerbased,methods,bert,xlmroberta,achieve,best,results,latter,achieving,fscore,previous,stateoftheart,moreover,use,ezafe,information,improve,persian,partofspeech,tagging,results,show,information,useful,transformerbased,methods,explain,might,case</th>\n",
       "      <th>various,difficulties,accomodating,traditional,masscount,distinction,grammar,english,goal,production,logical,form,semantic,translations,initial,english,sentences,present,paper,surveys,difficulties,one,puzzle,whether,distinction,syntactic,one,semantic,one,ie,whether,wellformedness,constraint,whether,description,semantic,translations,produced,another,puzzle,whether,applied,simple,words,occur,lexicon,whether,apply,longer,units,entire,nps,wide,variety,possible,theories,two,seem,produce,required,results,plausible,inferences,intuitively,satisfying,semantic,representations,two,theories,developed,compared</th>\n",
       "      <th>differently,phrasebased,paradigm,neural,machine,translation,nmt,operates,word,sentence,representations,continuous,space,makes,decoding,process,difficult,interpret,also,harder,influence,external,knowledge,latter,problem,effective,solutions,like,xmlmarkup,used,phrasebased,models,inject,fixed,translation,options,constraints,decoding,time,yet,available,propose,guide,mechanism,enhances,existing,nmt,decoder,ability,prioritize,adequately,handle,translation,options,presented,form,xml,annotations,source,words,positive,results,obtained,two,different,translation,tasks,indicate,effectiveness,approach</th>\n",
       "      <th>training,models,map,natural,language,instructions,programs,given,target,world,supervision,requires,searching,good,programs,training,time,search,commonly,done,using,beam,search,space,partial,programs,program,trees,length,instructions,grows,finding,good,program,becomes,difficult,work,propose,search,algorithm,uses,target,world,state,known,training,time,train,critic,network,predicts,expected,reward,every,search,state,score,search,states,beam,interpolating,expected,reward,likelihood,programs,represented,search,state,moreover,search,space,programs,compressed,state,program,executions,augmented,recent,entities,actions,scone,dataset,show,algorithm,dramatically,improves,performance,three,domains,compared,standard,beam,search,baselines</th>\n",
       "      <th>...</th>\n",
       "      <th>deep,neural,networks,excel,learning,labeled,data,achieve,stateoftheart,results,wide,array,natural,language,processing,tasks,contrast,learning,unlabeled,data,especially,domain,shift,remains,challenge,motivated,latest,advances,survey,review,neural,unsupervised,domain,adaptation,techniques,require,labeled,target,domain,data,challenging,yet,widely,applicable,setup,outline,methods,early,traditional,nonneural,methods,pretrained,model,transfer,also,revisit,notion,domain,uncover,bias,type,natural,language,processing,tasks,received,attention,lastly,outline,future,directions,particularly,broader,need,outofdistribution,generalization,future,nlp</th>\n",
       "      <th>fewshot,classification,requires,classifiers,adapt,new,classes,training,instances,stateoftheart,metalearning,approaches,maml,learn,initialize,fast,adapt,parameters,limited,instances,shown,promising,results,fewshot,classification,however,existing,metalearning,models,solely,rely,implicit,instancebased,statistics,thus,suffer,instance,unreliability,weak,interpretability,solve,problem,propose,novel,metainformation,guided,metalearning,miml,framework,semantic,concepts,classes,provide,strong,guidance,metalearning,initialization,adaptation,effect,model,establish,connections,instancebased,information,semanticbased,information,enables,effective,initialization,faster,adaptation,comprehensive,experimental,results,fewshot,relation,classification,demonstrate,effectiveness,proposed,framework,notably,miml,achieves,comparable,superior,performance,humans,one,shot,fewrel,evaluation</th>\n",
       "      <th>recent,years,large,pretrained,models,demonstrated,stateoftheart,performance,many,nlp,tasks,however,deployment,models,devices,limited,resources,challenging,due,models,large,computational,consumption,memory,requirements,moreover,need,considerable,amount,labeled,training,data,also,hinders,realworld,deployment,scenarios,model,distillation,shown,promising,results,reducing,model,size,computational,load,data,efficiency,paper,test,boundaries,bert,model,distillation,terms,model,compression,inference,efficiency,data,scarcity,show,classification,tasks,require,capturing,general,lexical,semantics,successfully,distilled,simple,efficient,models,require,relatively,small,amount,labeled,training,data,also,show,distillation,large,pretrained,models,effective,reallife,scenarios,limited,amounts,labeled,training,available</th>\n",
       "      <th>isolating,domaindependent,information,within,large,natural,language,system,offers,general,advantages,modular,design,greatly,enhances,portability,system,new,domains,explored,problem,isolating,domain,dependencies,within,two,large,natural,language,systems,one,generating,tabular,data,base,text,information,formatting,retrieving,information,data,base,describe,domain,information,schema,used,capture,domainspecific,information,indicate,information,used,throughout,two,systems</th>\n",
       "      <th>languages,vary,placement,multiple,adjectives,surrounding,noun,typically,exhibit,strong,intralanguage,tendencies,relative,order,adjectives,eg,preference,big,blue,box,english,grande,boîte,bleue,french,alsundūq,al,azraq,alkabı,r,arabic,advance,new,quantitative,account,adjective,order,across,typologicallydistinct,languages,based,maximizing,information,gain,model,addresses,leftright,asymmetry,frenchtype,ana,sequences,approach,aan,naa,orderings,without,appeal,mechanisms,find,across,languages,preferred,order,adjectives,mirrors,efficient,algorithm,maximizing,information,gain</th>\n",
       "      <th>chinese,spelling,check,csc,task,detect,correct,spelling,errors,chinese,text,stateoftheart,works,csc,task,adopt,bertbased,nonautoregressive,language,model,relies,output,independence,assumption,inappropriate,independence,assumption,prevents,bertbased,models,learning,dependencies,among,target,tokens,resulting,incoherent,problem,address,issue,propose,novel,architecture,named,dynamic,connected,networks,dcn,generates,candidate,chinese,characters,via,pinyin,enhanced,candidate,generator,utilizes,attentionbased,network,model,dependencies,two,adjacent,chinese,characters,experimental,results,show,proposed,method,achieves,new,stateoftheart,performance,three,humanannotated,datasets</th>\n",
       "      <th>natural,language,processing,many,methods,proposed,solve,ambiguity,problems,paper,propose,technique,combine,method,interactive,disambiguation,automatic,one,ambiguous,words,characteristic,method,accuracy,interactive,disambiguation,considered,method,solves,two,following,problems,combining,disambiguation,methods,interactive,disambiguation,executed,ambiguous,word,disambiguated,one,ambiguous,words,exist,sentence,method,defines,condition,executing,interaction,users,order,disambiguation,based,strategy,accuracy,result,maximized,considering,accuracy,interactive,disambiguation,automatic,one,using,method,user,interaction,controlled,holding,accuracy,results</th>\n",
       "      <th>help,individuals,express,better,quotation,recommendation,receiving,growing,attention,nevertheless,prior,efforts,focus,modeling,quotations,queries,separately,ignore,relationship,quotations,queries,work,introduce,transformation,matrix,directly,maps,query,representations,quotation,representations,better,learn,mapping,relationship,employ,mapping,loss,minimizes,distance,two,semantic,spaces,one,quotation,another,mappedquery,furthermore,explore,using,words,history,queries,interpret,figurative,language,quotations,quotationaware,attention,applied,top,history,queries,highlight,indicator,words,experiments,two,datasets,english,chinese,show,model,outperforms,previous,stateoftheart,models</th>\n",
       "      <th>recent,years,large,neural,networks,natural,language,generation,nlg,made,leaps,bounds,ability,generate,fluent,text,however,tasks,evaluating,quality,differences,nlg,systems,understanding,humans,perceive,generated,text,remain,crucial,difficult,system,demonstration,present,real,fake,text,roft,website,tackles,challenges,inviting,users,try,hand,detecting,machinegenerated,text,variety,domains,introduce,novel,evaluation,task,based,detecting,boundary,text,passage,starts,humanwritten,transitions,machinegenerated,show,preliminary,results,using,roft,evaluate,detection,machinegenerated,news,articles</th>\n",
       "      <th>paper,presents,results,wmt,shared,tasks,included,five,machine,translation,mt,tasks,standard,news,itdomain,biomedical,multimodal,pronoun,three,evaluation,tasks,metrics,tuning,runtime,estimation,mt,quality,automatic,postediting,task,bilingual,document,alignment,task,year,mt,systems,institutions,plus,anonymized,online,systems,submitted,translation,directions,news,translation,task,itdomain,task,received,submissions,institutions,directions,biomedical,task,received,submissions,systems,institutions,evaluation,automatic,manual,relative,ranking,point,scale,assessments,quality,estimation,task,three,subtasks,total,teams,submitting,entries,automatic,postediting,task,total,teams,submitting,entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 10464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        \\\n",
       "0  0.0   \n",
       "1  0.0   \n",
       "\n",
       "   rover,widely,used,method,combine,output,multiple,automatic,speech,recognition,asr,systems,though,effective,basic,approach,variants,suffer,potential,drawbacks,results,depend,order,hypotheses,used,feed,combination,process,ii,applied,combine,long,hypotheses,disregard,possible,differences,transcription,quality,local,level,iii,often,rely,word,confidence,information,address,issues,proposing,segmentbased,rover,hypothesis,ranking,obtained,confidenceindependent,asr,quality,estimation,method,results,english,data,iwslt,iwslt,evaluation,campaigns,significantly,outperform,standard,rover,approximate,two,strong,oracles  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "\n",
       "   propose,joint,event,temporal,relation,extraction,model,shared,representation,learning,structured,prediction,proposed,method,two,advantages,existing,work,first,improves,event,representation,allowing,event,relation,modules,share,contextualized,embeddings,neural,representation,learner,second,avoids,error,propagation,conventional,pipeline,systems,leveraging,structured,inference,learning,methods,assign,event,labels,temporal,relation,labels,jointly,experiments,show,proposed,method,improve,event,extraction,temporal,relation,extraction,stateoftheart,systems,endtoend,f,improved,two,benchmark,datasets,respectively  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "\n",
       "   introduce,new,features,incorporating,semantic,predicateargument,structures,machine,translation,mt,methods,focus,completeness,semantic,structures,translations,well,order,translated,semantic,roles,experiment,translation,rules,contain,core,arguments,predicates,source,side,mt,system,observe,using,rules,significantly,improves,translation,quality,also,present,new,semantic,feature,resembles,language,model,results,show,language,model,feature,also,significantly,improve,mt,results  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "   image,description,new,natural,language,generation,task,aim,generate,humanlike,description,image,evaluation,computergenerated,text,notoriously,difficult,problem,however,quality,image,descriptions,typically,measured,using,unigram,bleu,human,judgements,focus,paper,determine,correlation,automatic,measures,human,judgements,task,estimate,correlation,unigram,smoothed,bleu,ter,rougesu,meteor,human,judgements,two,data,sets,main,finding,unigram,bleu,weak,correlation,meteor,strongest,correlation,human,judgements  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "\n",
       "   paper,propose,architecture,machine,translation,mt,capable,obtaining,multilingual,sentence,representations,incorporating,intermediate,attention,bridge,shared,across,languages,train,model,languagespecific,encoders,decoders,connected,innerattention,layer,encoder,side,attention,bridge,exploits,semantics,language,translation,develops,languageagnostic,meaning,representation,efficiently,used,transfer,learning,present,new,framework,efficient,development,multilingual,neural,machine,translation,nmt,using,model,scheduled,training,tested,approach,systematic,way,multiparallel,data,set,model,achieves,substantial,improvements,strong,bilingual,models,performs,well,zeroshot,translation,demonstrates,ability,abstraction,transfer,learning  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "   ezafe,grammatical,particle,iranian,languages,links,two,words,together,regardless,important,information,conveys,almost,always,indicated,persian,script,resulting,mistakes,reading,complex,sentences,errors,natural,language,processing,tasks,paper,experiment,different,machine,learning,methods,achieve,stateoftheart,results,task,ezafe,recognition,transformerbased,methods,bert,xlmroberta,achieve,best,results,latter,achieving,fscore,previous,stateoftheart,moreover,use,ezafe,information,improve,persian,partofspeech,tagging,results,show,information,useful,transformerbased,methods,explain,might,case  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "   various,difficulties,accomodating,traditional,masscount,distinction,grammar,english,goal,production,logical,form,semantic,translations,initial,english,sentences,present,paper,surveys,difficulties,one,puzzle,whether,distinction,syntactic,one,semantic,one,ie,whether,wellformedness,constraint,whether,description,semantic,translations,produced,another,puzzle,whether,applied,simple,words,occur,lexicon,whether,apply,longer,units,entire,nps,wide,variety,possible,theories,two,seem,produce,required,results,plausible,inferences,intuitively,satisfying,semantic,representations,two,theories,developed,compared  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "   differently,phrasebased,paradigm,neural,machine,translation,nmt,operates,word,sentence,representations,continuous,space,makes,decoding,process,difficult,interpret,also,harder,influence,external,knowledge,latter,problem,effective,solutions,like,xmlmarkup,used,phrasebased,models,inject,fixed,translation,options,constraints,decoding,time,yet,available,propose,guide,mechanism,enhances,existing,nmt,decoder,ability,prioritize,adequately,handle,translation,options,presented,form,xml,annotations,source,words,positive,results,obtained,two,different,translation,tasks,indicate,effectiveness,approach  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "\n",
       "   training,models,map,natural,language,instructions,programs,given,target,world,supervision,requires,searching,good,programs,training,time,search,commonly,done,using,beam,search,space,partial,programs,program,trees,length,instructions,grows,finding,good,program,becomes,difficult,work,propose,search,algorithm,uses,target,world,state,known,training,time,train,critic,network,predicts,expected,reward,every,search,state,score,search,states,beam,interpolating,expected,reward,likelihood,programs,represented,search,state,moreover,search,space,programs,compressed,state,program,executions,augmented,recent,entities,actions,scone,dataset,show,algorithm,dramatically,improves,performance,three,domains,compared,standard,beam,search,baselines  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "\n",
       "   deep,neural,networks,excel,learning,labeled,data,achieve,stateoftheart,results,wide,array,natural,language,processing,tasks,contrast,learning,unlabeled,data,especially,domain,shift,remains,challenge,motivated,latest,advances,survey,review,neural,unsupervised,domain,adaptation,techniques,require,labeled,target,domain,data,challenging,yet,widely,applicable,setup,outline,methods,early,traditional,nonneural,methods,pretrained,model,transfer,also,revisit,notion,domain,uncover,bias,type,natural,language,processing,tasks,received,attention,lastly,outline,future,directions,particularly,broader,need,outofdistribution,generalization,future,nlp  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "   fewshot,classification,requires,classifiers,adapt,new,classes,training,instances,stateoftheart,metalearning,approaches,maml,learn,initialize,fast,adapt,parameters,limited,instances,shown,promising,results,fewshot,classification,however,existing,metalearning,models,solely,rely,implicit,instancebased,statistics,thus,suffer,instance,unreliability,weak,interpretability,solve,problem,propose,novel,metainformation,guided,metalearning,miml,framework,semantic,concepts,classes,provide,strong,guidance,metalearning,initialization,adaptation,effect,model,establish,connections,instancebased,information,semanticbased,information,enables,effective,initialization,faster,adaptation,comprehensive,experimental,results,fewshot,relation,classification,demonstrate,effectiveness,proposed,framework,notably,miml,achieves,comparable,superior,performance,humans,one,shot,fewrel,evaluation  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "\n",
       "   recent,years,large,pretrained,models,demonstrated,stateoftheart,performance,many,nlp,tasks,however,deployment,models,devices,limited,resources,challenging,due,models,large,computational,consumption,memory,requirements,moreover,need,considerable,amount,labeled,training,data,also,hinders,realworld,deployment,scenarios,model,distillation,shown,promising,results,reducing,model,size,computational,load,data,efficiency,paper,test,boundaries,bert,model,distillation,terms,model,compression,inference,efficiency,data,scarcity,show,classification,tasks,require,capturing,general,lexical,semantics,successfully,distilled,simple,efficient,models,require,relatively,small,amount,labeled,training,data,also,show,distillation,large,pretrained,models,effective,reallife,scenarios,limited,amounts,labeled,training,available  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "\n",
       "   isolating,domaindependent,information,within,large,natural,language,system,offers,general,advantages,modular,design,greatly,enhances,portability,system,new,domains,explored,problem,isolating,domain,dependencies,within,two,large,natural,language,systems,one,generating,tabular,data,base,text,information,formatting,retrieving,information,data,base,describe,domain,information,schema,used,capture,domainspecific,information,indicate,information,used,throughout,two,systems  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "\n",
       "   languages,vary,placement,multiple,adjectives,surrounding,noun,typically,exhibit,strong,intralanguage,tendencies,relative,order,adjectives,eg,preference,big,blue,box,english,grande,boîte,bleue,french,alsundūq,al,azraq,alkabı,r,arabic,advance,new,quantitative,account,adjective,order,across,typologicallydistinct,languages,based,maximizing,information,gain,model,addresses,leftright,asymmetry,frenchtype,ana,sequences,approach,aan,naa,orderings,without,appeal,mechanisms,find,across,languages,preferred,order,adjectives,mirrors,efficient,algorithm,maximizing,information,gain  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "   chinese,spelling,check,csc,task,detect,correct,spelling,errors,chinese,text,stateoftheart,works,csc,task,adopt,bertbased,nonautoregressive,language,model,relies,output,independence,assumption,inappropriate,independence,assumption,prevents,bertbased,models,learning,dependencies,among,target,tokens,resulting,incoherent,problem,address,issue,propose,novel,architecture,named,dynamic,connected,networks,dcn,generates,candidate,chinese,characters,via,pinyin,enhanced,candidate,generator,utilizes,attentionbased,network,model,dependencies,two,adjacent,chinese,characters,experimental,results,show,proposed,method,achieves,new,stateoftheart,performance,three,humanannotated,datasets  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "   natural,language,processing,many,methods,proposed,solve,ambiguity,problems,paper,propose,technique,combine,method,interactive,disambiguation,automatic,one,ambiguous,words,characteristic,method,accuracy,interactive,disambiguation,considered,method,solves,two,following,problems,combining,disambiguation,methods,interactive,disambiguation,executed,ambiguous,word,disambiguated,one,ambiguous,words,exist,sentence,method,defines,condition,executing,interaction,users,order,disambiguation,based,strategy,accuracy,result,maximized,considering,accuracy,interactive,disambiguation,automatic,one,using,method,user,interaction,controlled,holding,accuracy,results  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "   help,individuals,express,better,quotation,recommendation,receiving,growing,attention,nevertheless,prior,efforts,focus,modeling,quotations,queries,separately,ignore,relationship,quotations,queries,work,introduce,transformation,matrix,directly,maps,query,representations,quotation,representations,better,learn,mapping,relationship,employ,mapping,loss,minimizes,distance,two,semantic,spaces,one,quotation,another,mappedquery,furthermore,explore,using,words,history,queries,interpret,figurative,language,quotations,quotationaware,attention,applied,top,history,queries,highlight,indicator,words,experiments,two,datasets,english,chinese,show,model,outperforms,previous,stateoftheart,models  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "   recent,years,large,neural,networks,natural,language,generation,nlg,made,leaps,bounds,ability,generate,fluent,text,however,tasks,evaluating,quality,differences,nlg,systems,understanding,humans,perceive,generated,text,remain,crucial,difficult,system,demonstration,present,real,fake,text,roft,website,tackles,challenges,inviting,users,try,hand,detecting,machinegenerated,text,variety,domains,introduce,novel,evaluation,task,based,detecting,boundary,text,passage,starts,humanwritten,transitions,machinegenerated,show,preliminary,results,using,roft,evaluate,detection,machinegenerated,news,articles  \\\n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "   paper,presents,results,wmt,shared,tasks,included,five,machine,translation,mt,tasks,standard,news,itdomain,biomedical,multimodal,pronoun,three,evaluation,tasks,metrics,tuning,runtime,estimation,mt,quality,automatic,postediting,task,bilingual,document,alignment,task,year,mt,systems,institutions,plus,anonymized,online,systems,submitted,translation,directions,news,translation,task,itdomain,task,received,submissions,institutions,directions,biomedical,task,received,submissions,systems,institutions,evaluation,automatic,manual,relative,ranking,point,scale,assessments,quality,estimation,task,three,subtasks,total,teams,submitting,entries,automatic,postediting,task,total,teams,submitting,entries  \n",
       "0                                           0.000072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "1                                           0.000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "\n",
       "[2 rows x 10464 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
