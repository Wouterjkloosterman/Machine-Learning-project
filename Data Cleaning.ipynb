{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>10.18653/v1/W15-3402</td>\n",
       "      <td>A Factory of Comparable Corpora from Wikipedia</td>\n",
       "      <td>Multiple approaches to grab comparable data fr...</td>\n",
       "      <td>[Alberto Barrón-Cedeño, C. España-Bonet, Josu ...</td>\n",
       "      <td>BUCC@ACL/IJCNLP</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>53</td>\n",
       "      <td>[Wikipedia, Text corpus, Lexical analysis, Sta...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>10.3115/v1/W14-2205</td>\n",
       "      <td>Modeling the Noun Morphology of Plains Cree</td>\n",
       "      <td>This paper presents aspects of a computational...</td>\n",
       "      <td>[Conor Snoek, Dorothy Thunder, Kaidi Lõo, Antt...</td>\n",
       "      <td></td>\n",
       "      <td>2014.0</td>\n",
       "      <td>19</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Geography]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>10.18653/v1/P18-2086</td>\n",
       "      <td>End-Task Oriented Textual Entailment via Deep ...</td>\n",
       "      <td>This work deals with SciTail, a natural entail...</td>\n",
       "      <td>[Wenpeng Yin, D. Roth, Hinrich Schütze]</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>25</td>\n",
       "      <td>[Textual entailment, Interaction, Question ans...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>10.18653/v1/2021.naacl-industry.35</td>\n",
       "      <td>Training Language Models under Resource Constr...</td>\n",
       "      <td>BigE-retailer advertising delivers ad impressi...</td>\n",
       "      <td>[Eshwar Shamanna Girishekar, Shiv Surya, Nisha...</td>\n",
       "      <td>NAACL</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>10.18653/v1/2021.acl-short.136</td>\n",
       "      <td>SaRoCo: Detecting Satire in a Novel Romanian C...</td>\n",
       "      <td>In this work, we introduce a corpus for satire...</td>\n",
       "      <td>[Ana-Cristina Rogoz, Mihaela Găman, Radu Tudor...</td>\n",
       "      <td>ACL/IJCNLP</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>36</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doi  \\\n",
       "5924                10.18653/v1/W15-3402   \n",
       "116                  10.3115/v1/W14-2205   \n",
       "5728                10.18653/v1/P18-2086   \n",
       "5048  10.18653/v1/2021.naacl-industry.35   \n",
       "363       10.18653/v1/2021.acl-short.136   \n",
       "\n",
       "                                                  title  \\\n",
       "5924     A Factory of Comparable Corpora from Wikipedia   \n",
       "116         Modeling the Noun Morphology of Plains Cree   \n",
       "5728  End-Task Oriented Textual Entailment via Deep ...   \n",
       "5048  Training Language Models under Resource Constr...   \n",
       "363   SaRoCo: Detecting Satire in a Novel Romanian C...   \n",
       "\n",
       "                                               abstract  \\\n",
       "5924  Multiple approaches to grab comparable data fr...   \n",
       "116   This paper presents aspects of a computational...   \n",
       "5728  This work deals with SciTail, a natural entail...   \n",
       "5048  BigE-retailer advertising delivers ad impressi...   \n",
       "363   In this work, we introduce a corpus for satire...   \n",
       "\n",
       "                                                authors            venue  \\\n",
       "5924  [Alberto Barrón-Cedeño, C. España-Bonet, Josu ...  BUCC@ACL/IJCNLP   \n",
       "116   [Conor Snoek, Dorothy Thunder, Kaidi Lõo, Antt...                    \n",
       "5728            [Wenpeng Yin, D. Roth, Hinrich Schütze]              ACL   \n",
       "5048  [Eshwar Shamanna Girishekar, Shiv Surya, Nisha...            NAACL   \n",
       "363   [Ana-Cristina Rogoz, Mihaela Găman, Radu Tudor...       ACL/IJCNLP   \n",
       "\n",
       "        year  references                                             topics  \\\n",
       "5924  2015.0          53  [Wikipedia, Text corpus, Lexical analysis, Sta...   \n",
       "116   2014.0          19                                                 []   \n",
       "5728  2018.0          25  [Textual entailment, Interaction, Question ans...   \n",
       "5048  2021.0          28                                                 []   \n",
       "363   2021.0          36                                                 []   \n",
       "\n",
       "      is_open_access     fields_of_study  citations  \n",
       "5924            True  [Computer Science]         26  \n",
       "116             True         [Geography]         24  \n",
       "5728            True  [Computer Science]         16  \n",
       "5048           False  [Computer Science]          0  \n",
       "363            False  [Computer Science]          0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"train-1.json\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean topics\n",
    "topics = data['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2585    [App Store, Play Store, Natural language proce...\n",
       "7180                                                   []\n",
       "895     [Statistical machine translation, Linguistics,...\n",
       "7055    [Sentiment analysis, Multimodal interaction, E...\n",
       "6539    [Test set, Neural machine translation, Wikiped...\n",
       "4226                                                   []\n",
       "1856                                                   []\n",
       "9345                                                   []\n",
       "4851             [Computational linguistics, Computation]\n",
       "2831    [Context-sensitive language, Shallow parsing, ...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\",\".join(i) for i in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import nltk package\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all the topics to lower case \n",
    "import string\n",
    "topics = [doc.lower() for doc in topics] #Convert all the topics to lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization \n",
    "# Tokenization is essentially splitting a phrase, \n",
    "# sentence, paragraph, or an entire text document into smaller units, such as individual words or terms\n",
    "\n",
    "#word tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_docs = [word_tokenize(doc) for doc in topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = data['authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4479    [Toshiaki Nakazawa, S. Higashiyama, Chenchen D...\n",
       "4232             [A. Gispert, Gonzalo Iglesias, B. Byrne]\n",
       "3432    [Alexander Panchenko, Fide Marten, Eugen Ruppe...\n",
       "5785    [Xiang Hu, Haitao Mi, Zujie Wen, Yafang Wang, ...\n",
       "9322                                      [Liane Guillou]\n",
       "3055                                [K. Wołk, K. Marasek]\n",
       "920     [Junjie Huang, Duyu Tang, Linjun Shou, Ming Go...\n",
       "6928                  [Won Ik Cho, Woo Hyun Kang, N. Kim]\n",
       "7394                      [Shuhao Gu, Yang Feng, Qun Liu]\n",
       "678                         [Björn Rudzewitz, Ramon Ziai]\n",
       "Name: authors, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3592    Wikipedia is a resource of choice exploited in...\n",
      "9209    Artificial neural networks are powerful models...\n",
      "1026                                                     \n",
      "5975    In this paper, we describe our proposed method...\n",
      "2145    Neural methods for sentiment analysis have led...\n",
      "6670    This paper describes our unsupervised knowledg...\n",
      "6268    This paper describes our approach towards the ...\n",
      "4529    We present a hybrid knowledge-based approach t...\n",
      "7004    Incorporating source syntactic information int...\n",
      "4540    Existing automated essay scoring (AES) models ...\n",
      "8194    Author name disambiguation (AND) algorithms id...\n",
      "1390    This paper describes our two discourse parsers...\n",
      "3204    Despite significant progress in neural abstrac...\n",
      "9126    End-to-end models for speech translation (ST) ...\n",
      "62      INLG 2016 : The 9th International Natural Lang...\n",
      "7427    An essential operation in web corpus construct...\n",
      "3730    We use referential translation machines (RTM) ...\n",
      "7486    Answering complex questions that involve multi...\n",
      "649     User modeling is critical for many personalize...\n",
      "4697    Concept definition is important in language un...\n",
      "Name: abstract, dtype: object\n"
     ]
    }
   ],
   "source": [
    "abstract = data['abstract']\n",
    "abstract = abstract.fillna(\"\")\n",
    "abstract = abstract.sample(20)\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the transform\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and built vocab\n",
    "vectorizer.fit(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
