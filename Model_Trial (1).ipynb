{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = open(\"C:/Users/user/Desktop/ML_Challenge/train-1.json\")\n",
    "test_set = open(\"C:/Users/user/Desktop/ML_Challenge/test.json\")\n",
    "train = json.load(train_set)\n",
    "test = json.load(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.3115/v1/P15-1039</td>\n",
       "      <td>Generating High Quality Proposition Banks for ...</td>\n",
       "      <td>Semantic role labeling (SRL) is crucial to nat...</td>\n",
       "      <td>[A. Akbik, Laura Chiticariu, Marina Danilevsky...</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>39</td>\n",
       "      <td>[Semantic role labeling]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.18653/v1/2020.eval4nlp-1.12</td>\n",
       "      <td>One of these words is not like the other: a re...</td>\n",
       "      <td>Word embeddings are an active topic in the NLP...</td>\n",
       "      <td>[Jesper Brink Andersen, Mikkel Bak Bertelsen, ...</td>\n",
       "      <td>EVAL4NLP</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>44</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.18653/v1/W17-3516</td>\n",
       "      <td>The Code2Text Challenge: Text Generation in So...</td>\n",
       "      <td>We propose a new shared task for tactical data...</td>\n",
       "      <td>[Kyle Richardson, Sina Zarrieß, Jonas Kuhn]</td>\n",
       "      <td>INLG</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>30</td>\n",
       "      <td>[Natural language generation, Library (computi...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.18653/v1/S17-2160</td>\n",
       "      <td>The Meaning Factory at SemEval-2017 Task 9: Pr...</td>\n",
       "      <td>We evaluate a semantic parser based on a chara...</td>\n",
       "      <td>[Rik van Noord, Johan Bos]</td>\n",
       "      <td>SemEval@ACL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[Parsing, Convolutional neural network, Text-b...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.18653/v1/W15-2205</td>\n",
       "      <td>Semantic Parsing for Textual Entailment</td>\n",
       "      <td>In this paper we gauge the utility of general-...</td>\n",
       "      <td>[Elisabeth Lien, Milen Kouylekov]</td>\n",
       "      <td>IWPT</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[Textual entailment, Parsing, SemEval, Semanti...</td>\n",
       "      <td>True</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              doi  \\\n",
       "0             10.3115/v1/P15-1039   \n",
       "1  10.18653/v1/2020.eval4nlp-1.12   \n",
       "2            10.18653/v1/W17-3516   \n",
       "3            10.18653/v1/S17-2160   \n",
       "4            10.18653/v1/W15-2205   \n",
       "\n",
       "                                               title  \\\n",
       "0  Generating High Quality Proposition Banks for ...   \n",
       "1  One of these words is not like the other: a re...   \n",
       "2  The Code2Text Challenge: Text Generation in So...   \n",
       "3  The Meaning Factory at SemEval-2017 Task 9: Pr...   \n",
       "4            Semantic Parsing for Textual Entailment   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Semantic role labeling (SRL) is crucial to nat...   \n",
       "1  Word embeddings are an active topic in the NLP...   \n",
       "2  We propose a new shared task for tactical data...   \n",
       "3  We evaluate a semantic parser based on a chara...   \n",
       "4  In this paper we gauge the utility of general-...   \n",
       "\n",
       "                                             authors        venue    year  \\\n",
       "0  [A. Akbik, Laura Chiticariu, Marina Danilevsky...          ACL  2015.0   \n",
       "1  [Jesper Brink Andersen, Mikkel Bak Bertelsen, ...     EVAL4NLP  2020.0   \n",
       "2        [Kyle Richardson, Sina Zarrieß, Jonas Kuhn]         INLG  2017.0   \n",
       "3                         [Rik van Noord, Johan Bos]  SemEval@ACL  2017.0   \n",
       "4                  [Elisabeth Lien, Milen Kouylekov]         IWPT  2015.0   \n",
       "\n",
       "   references                                             topics  \\\n",
       "0          39                           [Semantic role labeling]   \n",
       "1          44                                                 []   \n",
       "2          30  [Natural language generation, Library (computi...   \n",
       "3          11  [Parsing, Convolutional neural network, Text-b...   \n",
       "4          26  [Textual entailment, Parsing, SemEval, Semanti...   \n",
       "\n",
       "   is_open_access     fields_of_study  citations  \n",
       "0            True  [Computer Science]         60  \n",
       "1            True  [Computer Science]          1  \n",
       "2            True  [Computer Science]          5  \n",
       "3            True  [Computer Science]          5  \n",
       "4            True  [Computer Science]         10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9658, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doi                  0\n",
       "title                0\n",
       "abstract           159\n",
       "authors              0\n",
       "venue                0\n",
       "year                 3\n",
       "references           0\n",
       "topics               0\n",
       "is_open_access       0\n",
       "fields_of_study    136\n",
       "citations            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"authors\"] = [\",\".join(i) for i in df_train[\"authors\"]]\n",
    "df_train[\"topics\"] = [\",\".join(i) for i in df_train[\"topics\"]]\n",
    "df_train[\"fields_of_study\"] = [\",\".join(i) for i in df_train[\"fields_of_study\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doi                   0\n",
       "title                 0\n",
       "abstract              0\n",
       "authors               0\n",
       "venue               403\n",
       "year                  0\n",
       "references            0\n",
       "topics             1940\n",
       "is_open_access        0\n",
       "fields_of_study       0\n",
       "citations             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_venue = df_train[\"venue\"].mode().values[0]\n",
    "#mode_venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[\"venue\"] = df_train[\"venue\"].fillna(mode_venue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_venue(text):\n",
    "    n = re.sub(r'[0-9]', \"\", text)\n",
    "    p = re.sub(r'[^\\w\\s]', \"\", n.lower().strip())\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"venue\"] = df_train[\"venue\"].apply(lambda x: clean_venue(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['venue_rank'] = df_train.groupby('venue')['citations'].rank(pct=True, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>citations</th>\n",
       "      <th>venue_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.3115/v1/P15-1039</td>\n",
       "      <td>Generating High Quality Proposition Banks for ...</td>\n",
       "      <td>Semantic role labeling (SRL) is crucial to nat...</td>\n",
       "      <td>A. Akbik,Laura Chiticariu,Marina Danilevsky,Yu...</td>\n",
       "      <td>acl</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>39</td>\n",
       "      <td>Semantic role labeling</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>60</td>\n",
       "      <td>0.232098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.18653/v1/W17-3516</td>\n",
       "      <td>The Code2Text Challenge: Text Generation in So...</td>\n",
       "      <td>We propose a new shared task for tactical data...</td>\n",
       "      <td>Kyle Richardson,Sina Zarrieß,Jonas Kuhn</td>\n",
       "      <td>inlg</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Natural language generation,Library (computing...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>5</td>\n",
       "      <td>0.556522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.18653/v1/S17-2160</td>\n",
       "      <td>The Meaning Factory at SemEval-2017 Task 9: Pr...</td>\n",
       "      <td>We evaluate a semantic parser based on a chara...</td>\n",
       "      <td>Rik van Noord,Johan Bos</td>\n",
       "      <td>semevalacl</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Parsing,Convolutional neural network,Text-base...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.18653/v1/W15-2205</td>\n",
       "      <td>Semantic Parsing for Textual Entailment</td>\n",
       "      <td>In this paper we gauge the utility of general-...</td>\n",
       "      <td>Elisabeth Lien,Milen Kouylekov</td>\n",
       "      <td>iwpt</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Textual entailment,Parsing,SemEval,Semantic We...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>10</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.18653/v1/K17-3015</td>\n",
       "      <td>A non-DNN Feature Engineering Approach to Depe...</td>\n",
       "      <td>For this year’s multilingual dependency parsin...</td>\n",
       "      <td>Xian Qian,Yang Liu</td>\n",
       "      <td>conll shared task</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Feature engineering,Parsing,Linear classifier,...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>4</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9649</th>\n",
       "      <td>10.18653/v1/P18-1241</td>\n",
       "      <td>Attacking Visual Language Grounding with Adver...</td>\n",
       "      <td>Visual language grounding is widely studied in...</td>\n",
       "      <td>Hongge Chen,Huan Zhang,Pin-Yu Chen,Jinfeng Yi,...</td>\n",
       "      <td>acl</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>44</td>\n",
       "      <td>Adversary (cryptography),Visual language</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>72</td>\n",
       "      <td>0.193245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>10.18653/v1/W16-2504</td>\n",
       "      <td>Evaluating Word Embeddings Using a Representat...</td>\n",
       "      <td>Word embeddings are increasingly used in natur...</td>\n",
       "      <td>Neha Nayak Kennard,Gabor Angeli,Christopher D....</td>\n",
       "      <td>repevalacl</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Word embedding,Microsoft Word for Mac,Natural ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>49</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>10.18653/v1/D19-1211</td>\n",
       "      <td>UR-FUNNY: A Multimodal Language Dataset for Un...</td>\n",
       "      <td>Humor is a unique and creative communicative b...</td>\n",
       "      <td>M. Hasan,Wasifur Rahman,Amir Zadeh,Jianyuan Zh...</td>\n",
       "      <td>emnlp</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Multimodal interaction,Natural language proces...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science,Mathematics</td>\n",
       "      <td>34</td>\n",
       "      <td>0.344731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9653</th>\n",
       "      <td>10.3115/v1/W14-0202</td>\n",
       "      <td>IBM’s Belief Tracker: Results On Dialog State ...</td>\n",
       "      <td>Accurate dialog state tracking is crucial for ...</td>\n",
       "      <td>Rudolf Kadlec,Jindřich Libovický,Jan Macek,Jan...</td>\n",
       "      <td>dmeacl</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Dialog system,Discriminative model,Inclusion B...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>8</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9657</th>\n",
       "      <td>10.3115/1075218.1075259</td>\n",
       "      <td>Headline Generation Based on Statistical Trans...</td>\n",
       "      <td>Extractive summarization techniques cannot gen...</td>\n",
       "      <td>Michele Banko,V. Mittal,M. Witbrock</td>\n",
       "      <td>acl</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Statistical machine translation,Approximation,...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>228</td>\n",
       "      <td>0.056374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7099 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi  \\\n",
       "0         10.3115/v1/P15-1039   \n",
       "2        10.18653/v1/W17-3516   \n",
       "3        10.18653/v1/S17-2160   \n",
       "4        10.18653/v1/W15-2205   \n",
       "5        10.18653/v1/K17-3015   \n",
       "...                       ...   \n",
       "9649     10.18653/v1/P18-1241   \n",
       "9650     10.18653/v1/W16-2504   \n",
       "9651     10.18653/v1/D19-1211   \n",
       "9653      10.3115/v1/W14-0202   \n",
       "9657  10.3115/1075218.1075259   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Generating High Quality Proposition Banks for ...   \n",
       "2     The Code2Text Challenge: Text Generation in So...   \n",
       "3     The Meaning Factory at SemEval-2017 Task 9: Pr...   \n",
       "4               Semantic Parsing for Textual Entailment   \n",
       "5     A non-DNN Feature Engineering Approach to Depe...   \n",
       "...                                                 ...   \n",
       "9649  Attacking Visual Language Grounding with Adver...   \n",
       "9650  Evaluating Word Embeddings Using a Representat...   \n",
       "9651  UR-FUNNY: A Multimodal Language Dataset for Un...   \n",
       "9653  IBM’s Belief Tracker: Results On Dialog State ...   \n",
       "9657  Headline Generation Based on Statistical Trans...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     Semantic role labeling (SRL) is crucial to nat...   \n",
       "2     We propose a new shared task for tactical data...   \n",
       "3     We evaluate a semantic parser based on a chara...   \n",
       "4     In this paper we gauge the utility of general-...   \n",
       "5     For this year’s multilingual dependency parsin...   \n",
       "...                                                 ...   \n",
       "9649  Visual language grounding is widely studied in...   \n",
       "9650  Word embeddings are increasingly used in natur...   \n",
       "9651  Humor is a unique and creative communicative b...   \n",
       "9653  Accurate dialog state tracking is crucial for ...   \n",
       "9657  Extractive summarization techniques cannot gen...   \n",
       "\n",
       "                                                authors              venue  \\\n",
       "0     A. Akbik,Laura Chiticariu,Marina Danilevsky,Yu...                acl   \n",
       "2               Kyle Richardson,Sina Zarrieß,Jonas Kuhn               inlg   \n",
       "3                               Rik van Noord,Johan Bos         semevalacl   \n",
       "4                        Elisabeth Lien,Milen Kouylekov               iwpt   \n",
       "5                                    Xian Qian,Yang Liu  conll shared task   \n",
       "...                                                 ...                ...   \n",
       "9649  Hongge Chen,Huan Zhang,Pin-Yu Chen,Jinfeng Yi,...                acl   \n",
       "9650  Neha Nayak Kennard,Gabor Angeli,Christopher D....         repevalacl   \n",
       "9651  M. Hasan,Wasifur Rahman,Amir Zadeh,Jianyuan Zh...              emnlp   \n",
       "9653  Rudolf Kadlec,Jindřich Libovický,Jan Macek,Jan...             dmeacl   \n",
       "9657                Michele Banko,V. Mittal,M. Witbrock                acl   \n",
       "\n",
       "        year  references                                             topics  \\\n",
       "0     2015.0          39                             Semantic role labeling   \n",
       "2     2017.0          30  Natural language generation,Library (computing...   \n",
       "3     2017.0          11  Parsing,Convolutional neural network,Text-base...   \n",
       "4     2015.0          26  Textual entailment,Parsing,SemEval,Semantic We...   \n",
       "5     2017.0          12  Feature engineering,Parsing,Linear classifier,...   \n",
       "...      ...         ...                                                ...   \n",
       "9649  2018.0          44           Adversary (cryptography),Visual language   \n",
       "9650  2016.0          15  Word embedding,Microsoft Word for Mac,Natural ...   \n",
       "9651  2019.0          52  Multimodal interaction,Natural language proces...   \n",
       "9653  2014.0          25  Dialog system,Discriminative model,Inclusion B...   \n",
       "9657  2000.0          38  Statistical machine translation,Approximation,...   \n",
       "\n",
       "      is_open_access               fields_of_study  citations  venue_rank  \n",
       "0               True              Computer Science         60    0.232098  \n",
       "2               True              Computer Science          5    0.556522  \n",
       "3               True              Computer Science          5    0.558824  \n",
       "4               True              Computer Science         10    0.187500  \n",
       "5               True              Computer Science          4    0.704545  \n",
       "...              ...                           ...        ...         ...  \n",
       "9649            True              Computer Science         72    0.193245  \n",
       "9650            True              Computer Science         49    0.300000  \n",
       "9651            True  Computer Science,Mathematics         34    0.344731  \n",
       "9653            True              Computer Science          8    0.111111  \n",
       "9657            True              Computer Science        228    0.056374  \n",
       "\n",
       "[7099 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[[\"venue_rank\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[[\"citations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(Y_true, Y_pred):\n",
    "    y_true = np.log1p(np.maximum(0, Y_true))\n",
    "    y_pred = np.log1p(np.maximum(0, Y_pred))\n",
    "    return 1 - np.mean((y_true-y_pred)**2) / np.mean((y_true-np.mean(y_true))**2)\n",
    "\n",
    "def evaluate(gold_path, pred_path):\n",
    "    gold = { x['doi']: x['citations'] for x in json.load(open(gold_path)) }\n",
    "    pred = { x['doi']: x['citations'] for x in json.load(open(pred_path)) }\n",
    "    y_true = np.array([ gold[key] for key in gold ])\n",
    "    y_pred = np.array([ pred[key] for key in gold ])\n",
    "    return score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citations    0.156218\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0924977438819824"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"year\"] = df_train[\"year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"age_of_article\"] = [2021 - i for i in df_train['year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df_train[[\"authors\"]]\n",
    "authors['authors_k'] = authors['authors'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "authors['authors_p'] = [x.replace(\".\",\" \").split(',') for x in authors['authors_k']]\n",
    "df_train[\"authors\"] = authors['authors_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"authors\"] = [\",\".join(i) for i in df_train[\"authors\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def split_and_count(column):\n",
    "    lis = []\n",
    "    for i in column:\n",
    "        for j in i.split(\",\"):\n",
    "            lis.append(j)\n",
    "            counts = Counter(lis)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"author_counts\"] = df_train['authors'].apply(lambda x: len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(split_and_count(df_train[\"authors\"]).items()),columns = ['authors','counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_score(var1,var2,main_df,index): \n",
    "    k = 0\n",
    "    for i,j in zip(var1,var2):\n",
    "        if i in main_df[index]:\n",
    "            k += j\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"author_score\"] = [author_score(df[\"authors\"], df[\"counts\"],df_train[\"authors\"], each) for each in df_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['author_rank'] = df_train.groupby('author_score')['citations'].rank(pct=True, ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>citations</th>\n",
       "      <th>venue_rank</th>\n",
       "      <th>age_of_article</th>\n",
       "      <th>author_counts</th>\n",
       "      <th>author_score</th>\n",
       "      <th>author_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.3115/v1/P15-1039</td>\n",
       "      <td>Generating High Quality Proposition Banks for ...</td>\n",
       "      <td>Semantic role labeling (SRL) is crucial to nat...</td>\n",
       "      <td>a  akbik,laura chiticariu,marina danilevsky,yu...</td>\n",
       "      <td>acl</td>\n",
       "      <td>2015</td>\n",
       "      <td>39</td>\n",
       "      <td>Semantic role labeling</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>60</td>\n",
       "      <td>0.232098</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.879397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.18653/v1/W17-3516</td>\n",
       "      <td>The Code2Text Challenge: Text Generation in So...</td>\n",
       "      <td>We propose a new shared task for tactical data...</td>\n",
       "      <td>kyle richardson,sina zarrieß,jonas kuhn</td>\n",
       "      <td>inlg</td>\n",
       "      <td>2017</td>\n",
       "      <td>30</td>\n",
       "      <td>Natural language generation,Library (computing...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>5</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.18653/v1/S17-2160</td>\n",
       "      <td>The Meaning Factory at SemEval-2017 Task 9: Pr...</td>\n",
       "      <td>We evaluate a semantic parser based on a chara...</td>\n",
       "      <td>rik van noord,johan bos</td>\n",
       "      <td>semevalacl</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>Parsing,Convolutional neural network,Text-base...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.18653/v1/W15-2205</td>\n",
       "      <td>Semantic Parsing for Textual Entailment</td>\n",
       "      <td>In this paper we gauge the utility of general-...</td>\n",
       "      <td>elisabeth lien,milen kouylekov</td>\n",
       "      <td>iwpt</td>\n",
       "      <td>2015</td>\n",
       "      <td>26</td>\n",
       "      <td>Textual entailment,Parsing,SemEval,Semantic We...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>10</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.18653/v1/K17-3015</td>\n",
       "      <td>A non-DNN Feature Engineering Approach to Depe...</td>\n",
       "      <td>For this year’s multilingual dependency parsin...</td>\n",
       "      <td>xian qian,yang liu</td>\n",
       "      <td>conll shared task</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>Feature engineering,Parsing,Linear classifier,...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>4</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.159091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9649</th>\n",
       "      <td>10.18653/v1/P18-1241</td>\n",
       "      <td>Attacking Visual Language Grounding with Adver...</td>\n",
       "      <td>Visual language grounding is widely studied in...</td>\n",
       "      <td>hongge chen,huan zhang,pin-yu chen,jinfeng yi,...</td>\n",
       "      <td>acl</td>\n",
       "      <td>2018</td>\n",
       "      <td>44</td>\n",
       "      <td>Adversary (cryptography),Visual language</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>72</td>\n",
       "      <td>0.193245</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>10.18653/v1/W16-2504</td>\n",
       "      <td>Evaluating Word Embeddings Using a Representat...</td>\n",
       "      <td>Word embeddings are increasingly used in natur...</td>\n",
       "      <td>neha nayak kennard,gabor angeli,christopher d ...</td>\n",
       "      <td>repevalacl</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>Word embedding,Microsoft Word for Mac,Natural ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>49</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>10.18653/v1/D19-1211</td>\n",
       "      <td>UR-FUNNY: A Multimodal Language Dataset for Un...</td>\n",
       "      <td>Humor is a unique and creative communicative b...</td>\n",
       "      <td>m  hasan,wasifur rahman,amir zadeh,jianyuan zh...</td>\n",
       "      <td>emnlp</td>\n",
       "      <td>2019</td>\n",
       "      <td>52</td>\n",
       "      <td>Multimodal interaction,Natural language proces...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science,Mathematics</td>\n",
       "      <td>34</td>\n",
       "      <td>0.344731</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.702454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9653</th>\n",
       "      <td>10.3115/v1/W14-0202</td>\n",
       "      <td>IBM’s Belief Tracker: Results On Dialog State ...</td>\n",
       "      <td>Accurate dialog state tracking is crucial for ...</td>\n",
       "      <td>rudolf kadlec,jindřich libovický,jan macek,jan...</td>\n",
       "      <td>dmeacl</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>Dialog system,Discriminative model,Inclusion B...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>8</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.451754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9657</th>\n",
       "      <td>10.3115/1075218.1075259</td>\n",
       "      <td>Headline Generation Based on Statistical Trans...</td>\n",
       "      <td>Extractive summarization techniques cannot gen...</td>\n",
       "      <td>michele banko,v  mittal,m  witbrock</td>\n",
       "      <td>acl</td>\n",
       "      <td>2000</td>\n",
       "      <td>38</td>\n",
       "      <td>Statistical machine translation,Approximation,...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>228</td>\n",
       "      <td>0.056374</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.980328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7099 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi  \\\n",
       "0         10.3115/v1/P15-1039   \n",
       "2        10.18653/v1/W17-3516   \n",
       "3        10.18653/v1/S17-2160   \n",
       "4        10.18653/v1/W15-2205   \n",
       "5        10.18653/v1/K17-3015   \n",
       "...                       ...   \n",
       "9649     10.18653/v1/P18-1241   \n",
       "9650     10.18653/v1/W16-2504   \n",
       "9651     10.18653/v1/D19-1211   \n",
       "9653      10.3115/v1/W14-0202   \n",
       "9657  10.3115/1075218.1075259   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Generating High Quality Proposition Banks for ...   \n",
       "2     The Code2Text Challenge: Text Generation in So...   \n",
       "3     The Meaning Factory at SemEval-2017 Task 9: Pr...   \n",
       "4               Semantic Parsing for Textual Entailment   \n",
       "5     A non-DNN Feature Engineering Approach to Depe...   \n",
       "...                                                 ...   \n",
       "9649  Attacking Visual Language Grounding with Adver...   \n",
       "9650  Evaluating Word Embeddings Using a Representat...   \n",
       "9651  UR-FUNNY: A Multimodal Language Dataset for Un...   \n",
       "9653  IBM’s Belief Tracker: Results On Dialog State ...   \n",
       "9657  Headline Generation Based on Statistical Trans...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     Semantic role labeling (SRL) is crucial to nat...   \n",
       "2     We propose a new shared task for tactical data...   \n",
       "3     We evaluate a semantic parser based on a chara...   \n",
       "4     In this paper we gauge the utility of general-...   \n",
       "5     For this year’s multilingual dependency parsin...   \n",
       "...                                                 ...   \n",
       "9649  Visual language grounding is widely studied in...   \n",
       "9650  Word embeddings are increasingly used in natur...   \n",
       "9651  Humor is a unique and creative communicative b...   \n",
       "9653  Accurate dialog state tracking is crucial for ...   \n",
       "9657  Extractive summarization techniques cannot gen...   \n",
       "\n",
       "                                                authors              venue  \\\n",
       "0     a  akbik,laura chiticariu,marina danilevsky,yu...                acl   \n",
       "2               kyle richardson,sina zarrieß,jonas kuhn               inlg   \n",
       "3                               rik van noord,johan bos         semevalacl   \n",
       "4                        elisabeth lien,milen kouylekov               iwpt   \n",
       "5                                    xian qian,yang liu  conll shared task   \n",
       "...                                                 ...                ...   \n",
       "9649  hongge chen,huan zhang,pin-yu chen,jinfeng yi,...                acl   \n",
       "9650  neha nayak kennard,gabor angeli,christopher d ...         repevalacl   \n",
       "9651  m  hasan,wasifur rahman,amir zadeh,jianyuan zh...              emnlp   \n",
       "9653  rudolf kadlec,jindřich libovický,jan macek,jan...             dmeacl   \n",
       "9657                michele banko,v  mittal,m  witbrock                acl   \n",
       "\n",
       "      year  references                                             topics  \\\n",
       "0     2015          39                             Semantic role labeling   \n",
       "2     2017          30  Natural language generation,Library (computing...   \n",
       "3     2017          11  Parsing,Convolutional neural network,Text-base...   \n",
       "4     2015          26  Textual entailment,Parsing,SemEval,Semantic We...   \n",
       "5     2017          12  Feature engineering,Parsing,Linear classifier,...   \n",
       "...    ...         ...                                                ...   \n",
       "9649  2018          44           Adversary (cryptography),Visual language   \n",
       "9650  2016          15  Word embedding,Microsoft Word for Mac,Natural ...   \n",
       "9651  2019          52  Multimodal interaction,Natural language proces...   \n",
       "9653  2014          25  Dialog system,Discriminative model,Inclusion B...   \n",
       "9657  2000          38  Statistical machine translation,Approximation,...   \n",
       "\n",
       "      is_open_access               fields_of_study  citations  venue_rank  \\\n",
       "0               True              Computer Science         60    0.232098   \n",
       "2               True              Computer Science          5    0.556522   \n",
       "3               True              Computer Science          5    0.558824   \n",
       "4               True              Computer Science         10    0.187500   \n",
       "5               True              Computer Science          4    0.704545   \n",
       "...              ...                           ...        ...         ...   \n",
       "9649            True              Computer Science         72    0.193245   \n",
       "9650            True              Computer Science         49    0.300000   \n",
       "9651            True  Computer Science,Mathematics         34    0.344731   \n",
       "9653            True              Computer Science          8    0.111111   \n",
       "9657            True              Computer Science        228    0.056374   \n",
       "\n",
       "      age_of_article  author_counts  author_score  author_rank  \n",
       "0                  6              6            14     0.879397  \n",
       "2                  4              3            21     0.200000  \n",
       "3                  4              2             8     0.280000  \n",
       "4                  6              2             5     0.617560  \n",
       "5                  4              2            27     0.159091  \n",
       "...              ...            ...           ...          ...  \n",
       "9649               3              5             8     0.908000  \n",
       "9650               5              3            37     0.580000  \n",
       "9651               2              7            18     0.702454  \n",
       "9653               7              4            10     0.451754  \n",
       "9657              21              3             6     0.980328  \n",
       "\n",
       "[7099 rows x 16 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic popularity/ranking based on average citation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age of an article/number of years since the article was published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_author = df_train[[\"author_rank\", \"venue_rank\"]]\n",
    "y_author = df_train[[\"citations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_v, y_t, y_v = train_test_split(X_author, y_author, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_t = ss.fit_transform(X_t)\n",
    "X_v = ss.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "linreg.fit(X_t,y_t)\n",
    "\n",
    "y_pred_auth = linreg.predict(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citations    0.312915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(y_v, y_pred_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "Stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_clean = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    text_rc = re.sub('[0-9]+', '', text_clean)\n",
    "    tokens = re.split('\\W+', text_rc)\n",
    "    text = [word for word in tokens if word not in Stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"abstract\"] = df_train[\"abstract\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"abstract\"] = [\" \".join(i) for i in df_train[\"abstract\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"title\"] = df_train[\"title\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"title\"] = [\" \".join(i) for i in df_train[\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = df_train[[\"topics\"]]\n",
    "topics['topics_k'] = topics['topics'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "topics['topics_p'] = [x.replace(\" \", \",\").replace(\"(\",\"\").replace(\")\",\"\").split(',') for x in topics['topics_k']]\n",
    "df_train[\"topics\"] = topics[\"topics_p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"topics\"] = [\" \".join(i) for i in df_train[\"topics\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>references</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>fields_of_study</th>\n",
       "      <th>citations</th>\n",
       "      <th>venue_rank</th>\n",
       "      <th>age_of_article</th>\n",
       "      <th>author_counts</th>\n",
       "      <th>author_score</th>\n",
       "      <th>author_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.3115/v1/P15-1039</td>\n",
       "      <td>generating high quality proposition banks mult...</td>\n",
       "      <td>semantic role labeling srl crucial natural lan...</td>\n",
       "      <td>a  akbik,laura chiticariu,marina danilevsky,yu...</td>\n",
       "      <td>acl</td>\n",
       "      <td>2015</td>\n",
       "      <td>39</td>\n",
       "      <td>[semantic, role, labeling]</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>60</td>\n",
       "      <td>0.232098</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.879397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.18653/v1/W17-3516</td>\n",
       "      <td>codetext challenge text generation source libr...</td>\n",
       "      <td>propose new shared task tactical datatotext ge...</td>\n",
       "      <td>kyle richardson,sina zarrieß,jonas kuhn</td>\n",
       "      <td>inlg</td>\n",
       "      <td>2017</td>\n",
       "      <td>30</td>\n",
       "      <td>[natural, language, generation, library, compu...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>5</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.18653/v1/S17-2160</td>\n",
       "      <td>meaning factory semeval task producing amrs ne...</td>\n",
       "      <td>evaluate semantic parser based characterbased ...</td>\n",
       "      <td>rik van noord,johan bos</td>\n",
       "      <td>semevalacl</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>[parsing, convolutional, neural, network, text...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.18653/v1/W15-2205</td>\n",
       "      <td>semantic parsing textual entailment</td>\n",
       "      <td>paper gauge utility generalpurpose opendomain ...</td>\n",
       "      <td>elisabeth lien,milen kouylekov</td>\n",
       "      <td>iwpt</td>\n",
       "      <td>2015</td>\n",
       "      <td>26</td>\n",
       "      <td>[textual, entailment, parsing, semeval, semant...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>10</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.18653/v1/K17-3015</td>\n",
       "      <td>nondnn feature engineering approach dependency...</td>\n",
       "      <td>year multilingual dependency parsing shared ta...</td>\n",
       "      <td>xian qian,yang liu</td>\n",
       "      <td>conll shared task</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>[feature, engineering, parsing, linear, classi...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>4</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.159091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9649</th>\n",
       "      <td>10.18653/v1/P18-1241</td>\n",
       "      <td>attacking visual language grounding adversaria...</td>\n",
       "      <td>visual language grounding widely studied moder...</td>\n",
       "      <td>hongge chen,huan zhang,pin-yu chen,jinfeng yi,...</td>\n",
       "      <td>acl</td>\n",
       "      <td>2018</td>\n",
       "      <td>44</td>\n",
       "      <td>[adversary, cryptography, visual, language]</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>72</td>\n",
       "      <td>0.193245</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>10.18653/v1/W16-2504</td>\n",
       "      <td>evaluating word embeddings using representativ...</td>\n",
       "      <td>word embeddings increasingly used natural lang...</td>\n",
       "      <td>neha nayak kennard,gabor angeli,christopher d ...</td>\n",
       "      <td>repevalacl</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>[word, embedding, microsoft, word, for, mac, n...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>49</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>10.18653/v1/D19-1211</td>\n",
       "      <td>urfunny multimodal language dataset understand...</td>\n",
       "      <td>humor unique creative communicative behavior o...</td>\n",
       "      <td>m  hasan,wasifur rahman,amir zadeh,jianyuan zh...</td>\n",
       "      <td>emnlp</td>\n",
       "      <td>2019</td>\n",
       "      <td>52</td>\n",
       "      <td>[multimodal, interaction, natural, language, p...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science,Mathematics</td>\n",
       "      <td>34</td>\n",
       "      <td>0.344731</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.702454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9653</th>\n",
       "      <td>10.3115/v1/W14-0202</td>\n",
       "      <td>ibm belief tracker results dialog state tracki...</td>\n",
       "      <td>accurate dialog state tracking crucial design ...</td>\n",
       "      <td>rudolf kadlec,jindřich libovický,jan macek,jan...</td>\n",
       "      <td>dmeacl</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>[dialog, system, discriminative, model, inclus...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>8</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.451754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9657</th>\n",
       "      <td>10.3115/1075218.1075259</td>\n",
       "      <td>headline generation based statistical translation</td>\n",
       "      <td>extractive summarization techniques cannot gen...</td>\n",
       "      <td>michele banko,v  mittal,m  witbrock</td>\n",
       "      <td>acl</td>\n",
       "      <td>2000</td>\n",
       "      <td>38</td>\n",
       "      <td>[statistical, machine, translation, approximat...</td>\n",
       "      <td>True</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>228</td>\n",
       "      <td>0.056374</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.980328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7099 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi  \\\n",
       "0         10.3115/v1/P15-1039   \n",
       "2        10.18653/v1/W17-3516   \n",
       "3        10.18653/v1/S17-2160   \n",
       "4        10.18653/v1/W15-2205   \n",
       "5        10.18653/v1/K17-3015   \n",
       "...                       ...   \n",
       "9649     10.18653/v1/P18-1241   \n",
       "9650     10.18653/v1/W16-2504   \n",
       "9651     10.18653/v1/D19-1211   \n",
       "9653      10.3115/v1/W14-0202   \n",
       "9657  10.3115/1075218.1075259   \n",
       "\n",
       "                                                  title  \\\n",
       "0     generating high quality proposition banks mult...   \n",
       "2     codetext challenge text generation source libr...   \n",
       "3     meaning factory semeval task producing amrs ne...   \n",
       "4                   semantic parsing textual entailment   \n",
       "5     nondnn feature engineering approach dependency...   \n",
       "...                                                 ...   \n",
       "9649  attacking visual language grounding adversaria...   \n",
       "9650  evaluating word embeddings using representativ...   \n",
       "9651  urfunny multimodal language dataset understand...   \n",
       "9653  ibm belief tracker results dialog state tracki...   \n",
       "9657  headline generation based statistical translation   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     semantic role labeling srl crucial natural lan...   \n",
       "2     propose new shared task tactical datatotext ge...   \n",
       "3     evaluate semantic parser based characterbased ...   \n",
       "4     paper gauge utility generalpurpose opendomain ...   \n",
       "5     year multilingual dependency parsing shared ta...   \n",
       "...                                                 ...   \n",
       "9649  visual language grounding widely studied moder...   \n",
       "9650  word embeddings increasingly used natural lang...   \n",
       "9651  humor unique creative communicative behavior o...   \n",
       "9653  accurate dialog state tracking crucial design ...   \n",
       "9657  extractive summarization techniques cannot gen...   \n",
       "\n",
       "                                                authors              venue  \\\n",
       "0     a  akbik,laura chiticariu,marina danilevsky,yu...                acl   \n",
       "2               kyle richardson,sina zarrieß,jonas kuhn               inlg   \n",
       "3                               rik van noord,johan bos         semevalacl   \n",
       "4                        elisabeth lien,milen kouylekov               iwpt   \n",
       "5                                    xian qian,yang liu  conll shared task   \n",
       "...                                                 ...                ...   \n",
       "9649  hongge chen,huan zhang,pin-yu chen,jinfeng yi,...                acl   \n",
       "9650  neha nayak kennard,gabor angeli,christopher d ...         repevalacl   \n",
       "9651  m  hasan,wasifur rahman,amir zadeh,jianyuan zh...              emnlp   \n",
       "9653  rudolf kadlec,jindřich libovický,jan macek,jan...             dmeacl   \n",
       "9657                michele banko,v  mittal,m  witbrock                acl   \n",
       "\n",
       "      year  references                                             topics  \\\n",
       "0     2015          39                         [semantic, role, labeling]   \n",
       "2     2017          30  [natural, language, generation, library, compu...   \n",
       "3     2017          11  [parsing, convolutional, neural, network, text...   \n",
       "4     2015          26  [textual, entailment, parsing, semeval, semant...   \n",
       "5     2017          12  [feature, engineering, parsing, linear, classi...   \n",
       "...    ...         ...                                                ...   \n",
       "9649  2018          44        [adversary, cryptography, visual, language]   \n",
       "9650  2016          15  [word, embedding, microsoft, word, for, mac, n...   \n",
       "9651  2019          52  [multimodal, interaction, natural, language, p...   \n",
       "9653  2014          25  [dialog, system, discriminative, model, inclus...   \n",
       "9657  2000          38  [statistical, machine, translation, approximat...   \n",
       "\n",
       "      is_open_access               fields_of_study  citations  venue_rank  \\\n",
       "0               True              Computer Science         60    0.232098   \n",
       "2               True              Computer Science          5    0.556522   \n",
       "3               True              Computer Science          5    0.558824   \n",
       "4               True              Computer Science         10    0.187500   \n",
       "5               True              Computer Science          4    0.704545   \n",
       "...              ...                           ...        ...         ...   \n",
       "9649            True              Computer Science         72    0.193245   \n",
       "9650            True              Computer Science         49    0.300000   \n",
       "9651            True  Computer Science,Mathematics         34    0.344731   \n",
       "9653            True              Computer Science          8    0.111111   \n",
       "9657            True              Computer Science        228    0.056374   \n",
       "\n",
       "      age_of_article  author_counts  author_score  author_rank  \n",
       "0                  6              6            14     0.879397  \n",
       "2                  4              3            21     0.200000  \n",
       "3                  4              2             8     0.280000  \n",
       "4                  6              2             5     0.617560  \n",
       "5                  4              2            27     0.159091  \n",
       "...              ...            ...           ...          ...  \n",
       "9649               3              5             8     0.908000  \n",
       "9650               5              3            37     0.580000  \n",
       "9651               2              7            18     0.702454  \n",
       "9653               7              4            10     0.451754  \n",
       "9657              21              3             6     0.980328  \n",
       "\n",
       "[7099 rows x 16 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = df_train[[\"abstract\"]]\n",
    "title = df_train[[\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "abstract[\"2nd_lemmatized\"] = abstract[\"abstract\"].apply(lambda text: lemmatize_words(text))\n",
    "title[\"title_lem\"] = title[\"title\"].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>address</th>\n",
       "      <th>aim</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>allow</th>\n",
       "      <th>analysis</th>\n",
       "      <th>annotate</th>\n",
       "      <th>annotation</th>\n",
       "      <th>...</th>\n",
       "      <th>tree</th>\n",
       "      <th>type</th>\n",
       "      <th>unsupervised</th>\n",
       "      <th>user</th>\n",
       "      <th>various</th>\n",
       "      <th>vector</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256945</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>0.217411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7099 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy   achieve  across  address  aim  algorithm     allow  analysis  \\\n",
       "0     0.000000  0.000000     0.0      0.0  0.0   0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000     0.0      0.0  0.0   0.000000  0.000000  0.000000   \n",
       "2     0.131021  0.000000     0.0      0.0  0.0   0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.038765     0.0      0.0  0.0   0.000000  0.000000  0.039513   \n",
       "4     0.000000  0.000000     0.0      0.0  0.0   0.000000  0.000000  0.113698   \n",
       "...        ...       ...     ...      ...  ...        ...       ...       ...   \n",
       "7094  0.000000  0.000000     0.0      0.0  0.0   0.355985  0.000000  0.000000   \n",
       "7095  0.000000  0.000000     0.0      0.0  0.0   0.000000  0.132793  0.000000   \n",
       "7096  0.000000  0.000000     0.0      0.0  0.0   0.000000  0.000000  0.000000   \n",
       "7097  0.217411  0.000000     0.0      0.0  0.0   0.000000  0.124346  0.000000   \n",
       "7098  0.000000  0.000000     0.0      0.0  0.0   0.000000  0.000000  0.000000   \n",
       "\n",
       "      annotate  annotation  ...      tree  type  unsupervised      user  \\\n",
       "0          0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "1          0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "2          0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "3          0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "4          0.0         0.0  ...  0.481226   0.0           0.0  0.000000   \n",
       "...        ...         ...  ...       ...   ...           ...       ...   \n",
       "7094       0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "7095       0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "7096       0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "7097       0.0         0.0  ...  0.000000   0.0           0.0  0.119908   \n",
       "7098       0.0         0.0  ...  0.000000   0.0           0.0  0.000000   \n",
       "\n",
       "      various  vector  way      well      word      work  \n",
       "0         0.0     0.0  0.0  0.000000  0.000000  0.000000  \n",
       "1         0.0     0.0  0.0  0.000000  0.000000  0.000000  \n",
       "2         0.0     0.0  0.0  0.000000  0.000000  0.000000  \n",
       "3         0.0     0.0  0.0  0.000000  0.000000  0.036086  \n",
       "4         0.0     0.0  0.0  0.000000  0.000000  0.000000  \n",
       "...       ...     ...  ...       ...       ...       ...  \n",
       "7094      0.0     0.0  0.0  0.000000  0.000000  0.000000  \n",
       "7095      0.0     0.0  0.0  0.000000  0.256945  0.000000  \n",
       "7096      0.0     0.0  0.0  0.000000  0.096703  0.000000  \n",
       "7097      0.0     0.0  0.0  0.096165  0.000000  0.000000  \n",
       "7098      0.0     0.0  0.0  0.000000  0.000000  0.000000  \n",
       "\n",
       "[7099 rows x 200 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', \n",
    "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                              max_features=200, stop_words = [\"also\", \"two\", \"use\", \"one\", \"without\"])  \n",
    "vectorized = vectorizer.fit_transform(abstract[\"2nd_lemmatized\"])\n",
    "pd.DataFrame(vectorized.toarray(),columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alignment', 'analysis', 'annotation', 'answer', 'approach', 'arabic',\n",
       "       'attention', 'automatic', 'base', 'case', 'chinese', 'classification',\n",
       "       'comprehension', 'context', 'corpus', 'crosslingual', 'data', 'deep',\n",
       "       'dependency', 'detect', 'detection', 'dialog', 'dialogue',\n",
       "       'disambiguation', 'discourse', 'document', 'domain', 'embeddings',\n",
       "       'emotion', 'english', 'entity', 'error', 'evaluation', 'event',\n",
       "       'extraction', 'feature', 'framework', 'generate', 'generation',\n",
       "       'grammar', 'graph', 'identification', 'identify', 'improve',\n",
       "       'information', 'joint', 'knowledge', 'label', 'language', 'learn',\n",
       "       'learning', 'lexical', 'linguistic', 'machine', 'method', 'model',\n",
       "       'morphological', 'multilingual', 'multimodal', 'name', 'natural',\n",
       "       'network', 'neural', 'news', 'nlp', 'online', 'parse', 'parsing',\n",
       "       'predict', 'prediction', 'question', 'recognition', 'relation',\n",
       "       'representation', 'segmentation', 'semantic', 'semantics', 'semeval',\n",
       "       'sentence', 'sentiment', 'sequence', 'share', 'similarity', 'social',\n",
       "       'speech', 'statistical', 'structure', 'study', 'summarization',\n",
       "       'syntactic', 'system', 'task', 'text', 'topic', 'towards', 'transfer',\n",
       "       'translation', 'twitter', 'unsupervised', 'word'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer(analyzer='word', \n",
    "                              token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                              max_features=100, stop_words = [\"also\", \"two\", \"use\", \"one\", \"without\", \"via\", \"wmt\"])  \n",
    "\n",
    "vectorized1 = vectorizer1.fit_transform(title[\"title_lem\"])\n",
    "pd.DataFrame(vectorized1.toarray(),columns=vectorizer1.get_feature_names()).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
